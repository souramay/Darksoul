{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HoY-ApPdVbBN5eg2yreL0WbU3XfBIH70",
      "authorship_tag": "ABX9TyP3tB4wQRGy9SM1Blw3CZrC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "389bdf5043b5446c8110d29bbfc9717a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d48a8f2549e4546801e71cd8f03a2ca",
              "IPY_MODEL_28ffc3f74c0549f186e1631b598b1e28",
              "IPY_MODEL_923f98c47293498c8eb0db8873725f23"
            ],
            "layout": "IPY_MODEL_5bddb3e6a73c4aeda8ae171537ba1ee6"
          }
        },
        "0d48a8f2549e4546801e71cd8f03a2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b15321094014054873910e95bd2c326",
            "placeholder": "​",
            "style": "IPY_MODEL_d91ddff323264e1aaf3cacaf4e82211e",
            "value": "llama-2-7b-chat.Q4_K_M.gguf: 100%"
          }
        },
        "28ffc3f74c0549f186e1631b598b1e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ec0ae03cb0e4772887078f3e725f5aa",
            "max": 4081004224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbd48d2a3d324cc2928a9caace687777",
            "value": 4081004224
          }
        },
        "923f98c47293498c8eb0db8873725f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2dd71a36ad47f69bad834ab7ca7d6a",
            "placeholder": "​",
            "style": "IPY_MODEL_e18b0538728848668629fb57276f9bb4",
            "value": " 4.08G/4.08G [00:33&lt;00:00, 196MB/s]"
          }
        },
        "5bddb3e6a73c4aeda8ae171537ba1ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b15321094014054873910e95bd2c326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d91ddff323264e1aaf3cacaf4e82211e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ec0ae03cb0e4772887078f3e725f5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd48d2a3d324cc2928a9caace687777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f2dd71a36ad47f69bad834ab7ca7d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18b0538728848668629fb57276f9bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souramay/Darksoul/blob/main/pdf_querry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing**"
      ],
      "metadata": {
        "id": "DMJsWwK5_AwR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPdCXSlN74Vp",
        "outputId": "59b1e03a-6c85-4c27-9be2-21d6bc22a3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.37)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: cassio in /usr/local/lib/python3.11/dist-packages (0.1.10)\n",
            "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /usr/local/lib/python3.11/dist-packages (from cassio) (3.29.2)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from cassio) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from cassio) (2.32.3)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.11/dist-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->cassio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->cassio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->cassio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->cassio) (2025.1.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (8.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.17.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install -U langchain-community\n",
        "!pip install -q cassio datasets langchain tiktoken\n",
        "!pip install -q llama-cpp-python sentence-transformers PyPDF2\n",
        "!pip install -U cassio\n",
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing model llama 2**"
      ],
      "metadata": {
        "id": "v8gF0vDk_LRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"TheBloke/Llama-2-7b-chat-GGUF\",\n",
        "    filename=\"llama-2-7b-chat.Q4_K_M.gguf\",\n",
        "    force_download=True,\n",
        "    cache_dir=\"/root/.cache/huggingface/hub\"\n",
        ")"
      ],
      "metadata": {
        "id": "PBFVBqev8GUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "389bdf5043b5446c8110d29bbfc9717a",
            "0d48a8f2549e4546801e71cd8f03a2ca",
            "28ffc3f74c0549f186e1631b598b1e28",
            "923f98c47293498c8eb0db8873725f23",
            "5bddb3e6a73c4aeda8ae171537ba1ee6",
            "2b15321094014054873910e95bd2c326",
            "d91ddff323264e1aaf3cacaf4e82211e",
            "8ec0ae03cb0e4772887078f3e725f5aa",
            "dbd48d2a3d324cc2928a9caace687777",
            "6f2dd71a36ad47f69bad834ab7ca7d6a",
            "e18b0538728848668629fb57276f9bb4"
          ]
        },
        "outputId": "78b2a644-438b-43bb-d4c9-a2fe8b9a5d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "389bdf5043b5446c8110d29bbfc9717a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining model path**"
      ],
      "metadata": {
        "id": "R300HrX2_RmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLAMA_MODEL_PATH = \"/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7b-chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf\""
      ],
      "metadata": {
        "id": "5jKyJxMs8Kxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "QC-Syvg1_WUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_community.embeddings import LlamaCppEmbeddings\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import fitz  # PyMuPDF\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import cassio\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "nLrNOsvS8P0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configuration**"
      ],
      "metadata": {
        "id": "yRFDX_5394sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"your_token\"\n",
        "ASTRA_DB_ID = \"your_id\"\n",
        "\n",
        "PDF_PATH = \"Kali_Linux_Guide.pdf\"\n",
        "KEYSPACE = \"default_keyspace\""
      ],
      "metadata": {
        "id": "Xi3gdPgf8bep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize Astra DB**"
      ],
      "metadata": {
        "id": "eeL8N8yc-BlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cassio.init(\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        "    database_id=ASTRA_DB_ID,\n",
        "    keyspace=KEYSPACE\n",
        ")\n"
      ],
      "metadata": {
        "id": "SWFxbez791_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and process PDF**"
      ],
      "metadata": {
        "id": "IRTxRTj8-LcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_and_chunk_pdf():\n",
        "    doc = fitz.open(PDF_PATH)\n",
        "    raw_text = \"\".join([page.get_text() for page in doc])\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    return text_splitter.split_text(raw_text)\n",
        "\n",
        "text_chunks = load_and_chunk_pdf()"
      ],
      "metadata": {
        "id": "ybw5iQ2W8gbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **text chunks**"
      ],
      "metadata": {
        "id": "jbWOf12SKQYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPFPV6z7KTRt",
        "outputId": "84cd807f-199c-4a27-f9d2-9273ecf2fb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Kali Linux: A Comprehensive Guide\\n## 1. Introduction to Kali Linux\\nKali Linux is a Debian-based Linux distribution developed by\\nOffensive Security, specifically designed for penetration testing,\\nethical hacking, and cybersecurity research. It comes pre-installed\\nwith a vast collection of security tools and is widely used by security\\nprofessionals, ethical hackers, and digital forensic experts.\\n## 2. History and Development\\nKali Linux evolved from BackTrack Linux, another popular\\nsecurity-focused distribution. In 2013, Offensive Security introduced\\nKali Linux as a more robust and flexible alternative, incorporating a\\nrolling release model to ensure continuous updates.\\n## 3. Features of Kali Linux\\n- Pre-installed Security Tools: Comes with over 600 tools for',\n",
              " 'rolling release model to ensure continuous updates.\\n## 3. Features of Kali Linux\\n- Pre-installed Security Tools: Comes with over 600 tools for\\npenetration testing, forensic analysis, and network security.\\n- Customizable and Open-source: Users can modify the OS to fit\\nspecific security needs.\\n- Live Boot & Persistent Mode: Run directly from a USB drive without\\ninstallation.\\n- Support for Multiple Architectures: Works on x86, x64, and ARM\\narchitectures.\\n- Rolling Release Model: Ensures access to the latest tools and\\nupdates.\\n## 4. Installing Kali Linux\\n### 4.1 System Requirements\\n- Minimum 2GB RAM (4GB recommended)\\n- 20GB of free disk space\\n- 64-bit or 32-bit processor\\n- Bootable USB drive or DVD\\n### 4.2 Installation Steps\\n1. Download the latest Kali Linux ISO from the official website.',\n",
              " '- 20GB of free disk space\\n- 64-bit or 32-bit processor\\n- Bootable USB drive or DVD\\n### 4.2 Installation Steps\\n1. Download the latest Kali Linux ISO from the official website.\\n2. Create a bootable USB using tools like Rufus or Balena Etcher.\\n3. Boot from the USB and start the installation process.\\n4. Follow on-screen instructions to configure disk partitions, user\\ncredentials, and system preferences.\\n5. Reboot and log in to start using Kali Linux.\\n## 5. Basic Kali Linux Commands\\n### 5.1 File System Navigation\\n- ls - List directory contents\\n- cd - Change directory\\n- pwd - Print working directory\\n- cp - Copy files and directories\\n- mv - Move or rename files\\n### 5.2 User and System Management\\n- whoami - Displays the current user\\n- passwd - Change user password\\n- adduser - Create a new user',\n",
              " '- cp - Copy files and directories\\n- mv - Move or rename files\\n### 5.2 User and System Management\\n- whoami - Displays the current user\\n- passwd - Change user password\\n- adduser - Create a new user\\n- shutdown -h now - Shutdown system\\n- reboot - Restart system\\n## 6. Essential Tools in Kali Linux\\n### 6.1 Network Scanning and Reconnaissance\\n- Nmap: Network discovery and security auditing.\\n- Wireshark: Packet analysis and monitoring.\\n- Netcat: Reading and writing data across networks.\\n### 6.2 Exploitation Tools\\n- Metasploit Framework: Automates vulnerability exploitation.\\n- SQLmap: Detects and exploits SQL injection vulnerabilities.\\n- John the Ripper: Password cracking tool.\\n### 6.3 Digital Forensics and Reverse Engineering\\n- Autopsy: Digital forensic analysis.',\n",
              " '- SQLmap: Detects and exploits SQL injection vulnerabilities.\\n- John the Ripper: Password cracking tool.\\n### 6.3 Digital Forensics and Reverse Engineering\\n- Autopsy: Digital forensic analysis.\\n- Volatility: Memory forensics framework.\\n- Radare2: Reverse engineering tool.\\n## 7. Ethical Hacking Workflow Using Kali Linux\\n1. Information Gathering - Use Nmap and Recon-ng to map targets.\\n2. Vulnerability Analysis - Identify weak points using OpenVAS.\\n3. Exploitation - Gain access using Metasploit.\\n4. Post-exploitation - Maintain access using persistence techniques.\\n5. Reporting - Document findings using Dradis or other reporting\\ntools.\\n## 8. Advanced Kali Linux Techniques\\n- Customizing Kali: Installing additional tools and modifying\\nconfigurations.',\n",
              " '5. Reporting - Document findings using Dradis or other reporting\\ntools.\\n## 8. Advanced Kali Linux Techniques\\n- Customizing Kali: Installing additional tools and modifying\\nconfigurations.\\n- Using Kali in Virtual Machines: Running in VMware or VirtualBox.\\n- Kali Linux on ARM Devices: Installing on Raspberry Pi and other\\nARM-based hardware.\\n## 9. Ethical Considerations and Responsible Hacking\\nUsing Kali Linux comes with ethical responsibilities. Always ensure:\\n- Permission is obtained before testing systems.\\n- Responsible disclosure of vulnerabilities.\\n- Compliance with cybersecurity laws.\\n## 10. Conclusion\\nKali Linux is a powerful tool for security professionals and ethical\\nhackers. With its vast array of tools and flexibility, it remains one of',\n",
              " '- Compliance with cybersecurity laws.\\n## 10. Conclusion\\nKali Linux is a powerful tool for security professionals and ethical\\nhackers. With its vast array of tools and flexibility, it remains one of\\nthe most widely used penetration testing distributions. However,\\nethical considerations must always be observed to ensure legal and\\nresponsible use.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize models**"
      ],
      "metadata": {
        "id": "4INd36G2-UOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=LLAMA_MODEL_PATH,\n",
        "    n_ctx=2048,\n",
        "    n_gpu_layers=40,\n",
        "    n_threads=8,\n",
        "    temperature=0.1,  # Lower temperature for more factual responses\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "embeddings = LlamaCppEmbeddings(\n",
        "    model_path=LLAMA_MODEL_PATH,\n",
        "    n_ctx=512\n",
        ")"
      ],
      "metadata": {
        "id": "u7CoFsig8nR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc304779-d58f-45a9-d9e0-02ffd953cf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_init_from_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7b-chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V2\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 3.80 GiB (4.84 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1684 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 4096\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 32\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 4096\n",
            "print_info: n_embd_v_gqa     = 4096\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 11008\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 6.74 B\n",
            "print_info: general.name     = LLaMA v2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  3891.24 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 512\n",
            "llama_init_from_model: n_ctx_per_seq = 512\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_init_from_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.02 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =    70.50 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and populate vector **store**"
      ],
      "metadata": {
        "id": "bSbsRijx-YiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vector_store = Cassandra(\n",
        "    embedding=embeddings,\n",
        "    table_name=\"pdf_qa_store\",\n",
        "    keyspace=KEYSPACE\n",
        ")\n"
      ],
      "metadata": {
        "id": "FUolJ1W08uRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c725e060-a568-46e9-8115-f5ff734dabb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    5717.94 ms\n",
            "llama_perf_context_print: prompt eval time =    5675.35 ms /     7 tokens (  810.76 ms per token,     1.23 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5719.46 ms /     8 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch insert with progress **tracking**"
      ],
      "metadata": {
        "id": "DcWz8RE7-cLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 10\n",
        "for i in range(0, len(text_chunks), BATCH_SIZE):\n",
        "    batch = text_chunks[i:i+BATCH_SIZE]\n",
        "    vector_store.add_texts(batch)\n",
        "    print(f\"Inserted batch {i//BATCH_SIZE + 1}/{(len(text_chunks)-1)//BATCH_SIZE + 1}\")"
      ],
      "metadata": {
        "id": "DUZD5Ttd8xPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom prompt template enforcing strict context-based **answers**"
      ],
      "metadata": {
        "id": "llNSGuXP-fdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "STRICT_PROMPT = \"\"\"Use the context below to answer the question. If the answer isn't clearly explained in the context,\n",
        "respond with \"This information is not covered in the document.\"\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=STRICT_PROMPT,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "01D0F7Z285dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create QA chain with optimized retriever **settings**"
      ],
      "metadata": {
        "id": "95mmDtfW-kBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(\n",
        "        search_type=\"similarity\",  # Changed from \"mmr\" to \"similarity\"\n",
        "        search_kwargs={\"k\": 5}  # Retrieve the top 5 most relevant passages\n",
        "    ),\n",
        "    chain_type_kwargs={\"prompt\": PROMPT},\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "-97VUvG_88D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **validating response**"
      ],
      "metadata": {
        "id": "tDGNNAFF-w43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_response(response: str, sources: list) -> bool:\n",
        "    \"\"\"Validate if answer content exists in retrieved source documents.\"\"\"\n",
        "    if not sources:\n",
        "        return False  # No source means no valid answer\n",
        "\n",
        "    # Allow default response to pass validation\n",
        "    if \"not covered in the document\" in response.lower():\n",
        "        return True\n",
        "\n",
        "    # Convert source text into a single lowercase string\n",
        "    source_text = \" \".join([doc.page_content.lower() for doc in sources])\n",
        "\n",
        "    # Extract meaningful words from response (excluding common stopwords)\n",
        "    stopwords = {\"the\", \"a\", \"an\", \"is\", \"in\", \"of\", \"and\", \"to\"}\n",
        "    answer_keywords = set(response.lower().split()) - stopwords\n",
        "\n",
        "    # Check if at least one keyword from response exists in the source text\n",
        "    return any(keyword in source_text for keyword in answer_keywords)"
      ],
      "metadata": {
        "id": "e-bav8Z48-6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taking query input until exit or quit is typed**"
      ],
      "metadata": {
        "id": "lV9DE32f-3Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive QA loop with validation\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"\\nQuestion (type 'exit' to quit): \").strip()\n",
        "        if query.lower() in (\"exit\", \"quit\", \"q\"):\n",
        "            break\n",
        "\n",
        "        result = qa_chain.invoke({\"query\": query})\n",
        "        response = result[\"result\"]\n",
        "        sources = result[\"source_documents\"]\n",
        "\n",
        "        # First check: If no sources found\n",
        "        if not sources:\n",
        "            response = \"This information is not covered in the document.\"\n",
        "        # Second check: Validate answer against sources\n",
        "        if not validate_response(response, sources):\n",
        "            response = \"This information is not covered in the document.\"\n",
        "\n",
        "        # Display final answer\n",
        "        print(f\"\\nANSWER: {response}\")\n",
        "\n",
        "        # Display source references\n",
        "        if sources:\n",
        "            print(\"\\nSOURCE REFERENCES:\")\n",
        "            for i, doc in enumerate(sources[:3], 1):  # Limit to 3 sources\n",
        "                print(f\"[Reference {i}] {doc.page_content[:200]}...\")  # Show first 200 chars\n",
        "        else:\n",
        "            print(\"\\nNo supporting documents found.\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "print(\"\\nSession ended.\")\n"
      ],
      "metadata": {
        "id": "bIlDxtq39Vsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffc6ec0-9a3a-4427-b2cb-36e39c11b8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question (type 'exit' to quit): what are the recommed of kali tools\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    5717.94 ms\n",
            "llama_perf_context_print: prompt eval time =    5491.41 ms /    10 tokens (  549.14 ms per token,     1.82 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5539.31 ms /    11 tokens\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ANSWER: \n",
            "The document provides information on the features, installation process, and basic commands of Kali Linux. However, it does not cover the recommended tools for ethical hacking or digital forensics using Kali Linux. To answer this question, you would need to consult other resources or expert opinions on the topic. Therefore, I respond with \"This information is not covered in the document.\"\n",
            "\n",
            "SOURCE REFERENCES:\n",
            "[Reference 1] Kali Linux: A Comprehensive Guide\n",
            "## 1. Introduction to Kali Linux\n",
            "Kali Linux is a Debian-based Linux distribution developed by\n",
            "Offensive Security, specifically designed for penetration testing,\n",
            "ethic...\n",
            "[Reference 2] - 20GB of free disk space\n",
            "- 64-bit or 32-bit processor\n",
            "- Bootable USB drive or DVD\n",
            "### 4.2 Installation Steps\n",
            "1. Download the latest Kali Linux ISO from the official website.\n",
            "2. Create a bootable USB ...\n",
            "[Reference 3] rolling release model to ensure continuous updates.\n",
            "## 3. Features of Kali Linux\n",
            "- Pre-installed Security Tools: Comes with over 600 tools for\n",
            "penetration testing, forensic analysis, and network secur...\n",
            "\n",
            "Question (type 'exit' to quit): what are Basic Kali Linux Commands\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    5717.94 ms\n",
            "llama_perf_context_print: prompt eval time =    3821.57 ms /     9 tokens (  424.62 ms per token,     2.36 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3869.65 ms /    10 tokens\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ANSWER:  Basic Kali Linux Commands include:\n",
            "- ls - List directory contents\n",
            "- cd - Change directory\n",
            "- pwd - Print working directory\n",
            "- cp - Copy files and directories\n",
            "- mv - Move or rename files\n",
            "- whoami - Displays the current user\n",
            "- passwd - Change user password\n",
            "- adduser - Create a new user\n",
            "- shutdown -h now - Shutdown system\n",
            "- reboot - Restart system\n",
            "\n",
            "SOURCE REFERENCES:\n",
            "[Reference 1] Kali Linux: A Comprehensive Guide\n",
            "## 1. Introduction to Kali Linux\n",
            "Kali Linux is a Debian-based Linux distribution developed by\n",
            "Offensive Security, specifically designed for penetration testing,\n",
            "ethic...\n",
            "[Reference 2] - 20GB of free disk space\n",
            "- 64-bit or 32-bit processor\n",
            "- Bootable USB drive or DVD\n",
            "### 4.2 Installation Steps\n",
            "1. Download the latest Kali Linux ISO from the official website.\n",
            "2. Create a bootable USB ...\n",
            "[Reference 3] rolling release model to ensure continuous updates.\n",
            "## 3. Features of Kali Linux\n",
            "- Pre-installed Security Tools: Comes with over 600 tools for\n",
            "penetration testing, forensic analysis, and network secur...\n",
            "\n",
            "Question (type 'exit' to quit): what is kali\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    5717.94 ms\n",
            "llama_perf_context_print: prompt eval time =    2433.61 ms /     5 tokens (  486.72 ms per token,     2.05 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2486.77 ms /     6 tokens\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ANSWER:  Kali Linux is a Debian-based Linux distribution developed by Offensive Security, specifically designed for penetration testing, ethical hacking, and cybersecurity research. It comes pre-installed with a vast collection of security tools and is widely used by security professionals, ethical hackers, and digital forensic experts.\n",
            "\n",
            "SOURCE REFERENCES:\n",
            "[Reference 1] Kali Linux: A Comprehensive Guide\n",
            "## 1. Introduction to Kali Linux\n",
            "Kali Linux is a Debian-based Linux distribution developed by\n",
            "Offensive Security, specifically designed for penetration testing,\n",
            "ethic...\n",
            "[Reference 2] - 20GB of free disk space\n",
            "- 64-bit or 32-bit processor\n",
            "- Bootable USB drive or DVD\n",
            "### 4.2 Installation Steps\n",
            "1. Download the latest Kali Linux ISO from the official website.\n",
            "2. Create a bootable USB ...\n",
            "[Reference 3] rolling release model to ensure continuous updates.\n",
            "## 3. Features of Kali Linux\n",
            "- Pre-installed Security Tools: Comes with over 600 tools for\n",
            "penetration testing, forensic analysis, and network secur...\n",
            "\n",
            "Question (type 'exit' to quit): q\n",
            "\n",
            "Session ended.\n"
          ]
        }
      ]
    }
  ]
}